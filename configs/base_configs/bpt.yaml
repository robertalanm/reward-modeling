model_path: "robertmyers/bpt-ppo"
tokenizer_path: "EleutherAI/gpt-j-6B"
# model_path: "facebook/opt-30b" 
# tokenizer_path: "facebook/opt-30b"
save_dir: "../ckpts/bpt-ppo"

train_args:
  output_dir: "../ckpts/bpt-ppo"
  num_train_epochs: 2
  logging_steps: 100
  save_strategy: "epoch"
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 1
  warmup_steps: 100
  weight_decay: 0.01
  learning_rate: 9.65e-6
  save_total_limit: 1
  logging_dir: "./logs"
  fp16: False
  bf16: True
  evaluation_strategy: "epoch"


# data_path: "Dahoas/sft-synthetic-hh"
data_path: "robertmyers/bpt-static"
# data_path: "Dahoas/sft-hh-rlhf"

